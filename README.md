
# RL Agent for Frozen Lake

This repository contains an implementation of reinforcement learning agents to solve the **Frozen Lake** environment using **Monte Carlo** and **SARSA** algorithms. The project demonstrates the use of reinforcement learning techniques to solve sequential decision-making problems in a simulated grid world.

---

## Overview

The Frozen Lake environment is a benchmark problem in reinforcement learning. The agent must navigate a grid world to reach the goal while avoiding holes, using two key algorithms:

1. **Monte Carlo Method**: Learns by observing complete episodes and using averaged rewards for policy updates.
2. **SARSA Algorithm**: An on-policy temporal-difference method to learn Q-values.

---

## Features

- Implementation of **Monte Carlo** and **SARSA** algorithms.
- Clear documentation with code explanations.
- Visualization of rewards and policy convergence.
- Code written for easy customization and reproducibility.

---

## Repository Structure

```
RL-Agent-Frozen-Lake/
├── Frozen_Lake_RL_Agent.ipynb  # Main Jupyter Notebook for the project
├── requirements.txt            # Required Python libraries
└── README.md                   # Project description and instructions
```

---

## How to Use

### 1. Clone the Repository
```bash
git clone https://github.com/melekkuru/RL-Agent-Frozen-Lake.git
cd RL-Agent-Frozen-Lake
```

### 2. Install Dependencies
Ensure you have Python installed. Use the following command to install the required libraries:
```bash
pip install -r requirements.txt
```

### 3. Run the Notebook
Open the Jupyter Notebook to explore and run the implementation:
```bash
jupyter notebook Frozen_Lake_RL_Agent.ipynb
```

---

## Key Results

- Both **Monte Carlo** and **SARSA** agents solve the Frozen Lake environment effectively.
- Reward trends and policy convergence are visualized in the notebook.

---

## Skills Demonstrated

- Reinforcement Learning
- Monte Carlo Methods
- SARSA Algorithm
- Python Programming
- Data Visualization with Matplotlib

---

## License

This project is licensed under the MIT License. Feel free to use, modify, and share!
```

You can paste this into your repository's `README.md` file. Let me know if you need any changes!
